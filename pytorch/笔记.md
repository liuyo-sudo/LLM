## pytorch学习笔记

### 张量



### 秩
    使用 torch.svd 或 torch.qr 快速计算秩
```python
import torch
# 定义矩阵
A = torch.tensor([[1., 2., 3.], [2., 4., 6.], [1., 1., 0.]])

# 方法 1：SVD 计算秩
_, S, _ = torch.svd(A)
rank = torch.sum(S > 1e-5).item()
print(f"通过 SVD 计算的秩: {rank}")

# 方法 2：行简化（QR 分解近似）
Q, R = torch.qr(A)
non_zero_rows = torch.sum(torch.abs(torch.diag(R)) > 1e-5).item()
print(f"通过 QR 分解计算的秩: {non_zero_rows}")


import numpy as np
A = np.array([[1, 2, 3], [2, 4, 6], [1, 1, 0]])
_, s, _ = np.linalg.svd(A)
rank = np.sum(s > 1e-10)  # 非零奇异值数量
print(rank)  # 输出：2
```
### pytorch训练流程
1、数据准备  D
2、定义模型 M
3、设置损失函数和优化器 L
4、训练循环 T
5、验证/评估 V
6、保存和加载模型 S
7、测试和推理 T

### 梯度
梯队下降：通过计算损失函数与模型参数的梯度，沿着梯队反方向不断更新参数，以逐渐减少损失

1、初始化参数
2、前向传播
3、计算损失
4、计算梯度
5、更新参数
6、迭代

