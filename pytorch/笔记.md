## pytorch学习笔记

### 张量

### 秩
    使用 torch.svd 或 torch.qr 快速计算秩
```python
import torch
# 定义矩阵
A = torch.tensor([[1., 2., 3.], [2., 4., 6.], [1., 1., 0.]])

# 方法 1：SVD 计算秩
_, S, _ = torch.svd(A)
rank = torch.sum(S > 1e-5).item()
print(f"通过 SVD 计算的秩: {rank}")

# 方法 2：行简化（QR 分解近似）
Q, R = torch.qr(A)
non_zero_rows = torch.sum(torch.abs(torch.diag(R)) > 1e-5).item()
print(f"通过 QR 分解计算的秩: {non_zero_rows}")


import numpy as np
A = np.array([[1, 2, 3], [2, 4, 6], [1, 1, 0]])
_, s, _ = np.linalg.svd(A)
rank = np.sum(s > 1e-10)  # 非零奇异值数量
print(rank)  # 输出：2
```
### pytorch训练流程
- 1、数据准备  D
- 2、定义模型 M
- 3、设置损失函数和优化器 L
- 4、训练循环 T
- 5、验证/评估 V
- 6、保存和加载模型 S
- 7、测试和推理 T

### 梯度
梯队下降：通过计算损失函数与模型参数的梯度，沿着梯队反方向不断更新参数，以逐渐减少损失

- 1、初始化参数
- 2、前向传播
- 3、计算损失
- 4、计算梯度
- 5、更新参数
- 6、迭代


### 优化器
- SGD
  - torch.optim.SGD 是 PyTorch 中实现的随机梯度下降（Stochastic Gradient Descent, SGD）优化器，
  - 支持标准 SGD、动量法（Momentum）、Nesterov 动量法、权重衰减（Weight Decay）等功能。
  - 它是最基础且广泛使用的优化器，适用于各种深度学习任务。
  - 参数说明:
    - params: 模型的可优化参数（通常是 model.parameters()），即 $\theta_0$。
    - lr: 学习率（$\gamma$），默认 0.001，控制参数更新的步长。
    - momentum: 动量系数（$\mu$），默认 0，控制历史梯度的累积，典型值如 0.9。
    - dampening: 动量阻尼系数（$\tau$），默认 0，降低当前梯度对动量的影响。
    - weight_decay: 权重衰减系数（$\lambda$），默认 0，添加 L2 正则化项。
    - nesterov: 布尔值，默认 False，是否启用 Nesterov 动量法。
    - maximize: 布尔值，默认 False，决定优化目标是最大化（True）还是最小化（False）损失函数。
    - foreach: 是否使用 foreach 实现以提高性能（None 表示自动选择）。
    - differentiable: 是否支持可微优化（实验性功能，默认 False）。
    - fused: 是否使用融合实现（优化性能，默认 None，视硬件支持）。
  - 输入参数：
    - $\gamma$: 学习率（lr），控制更新步长。
    - $\theta_0$: 初始参数（params）。
    - $f(\theta)$: 目标函数（损失函数）。
    - $\lambda$: 权重衰减系数（weight_decay）。
    - $\mu$: 动量系数（momentum）。
    - $\tau$: 阻尼系数（dampening）。
    - nesterov: 是否使用 Nesterov 动量。
    - maximize: 是否最大化目标函数。
  - 计算梯度:
    - $ g_t = \nabla_\theta f_t(\theta_{t-1}) $
      - 计算当前参数 $\theta_{t-1}$ 处的梯度 $g_t$，即目标函数对参数的偏导数。
    - 权重衰减:
      - $ \text{if } \lambda \neq 0: \quad g_t \leftarrow g_t + \lambda \theta_{t-1} $
        - 如果设置了权重衰减（$\lambda > 0$），在梯度中加入正则化项 $\lambda \theta_{t-1}$，等效于 L2 正则化，惩罚参数的大小，增强模型泛化能力。
    - 动量更新:
      - $ \text{if } \mu \neq 0: $
        - 如果启用了动量（$\mu > 0$）：
        - 对于 $t > 1$：$ b_t = \mu b_{t-1} + (1 - \tau) g_t $
          - $b_t$ 是动量（速度），结合历史动量 $b_{t-1}$ 和当前梯度 $g_t$。
          - $\mu b_{t-1}$: 保留历史动量。
          - $(1 - \tau) g_t$: 当前梯度的贡献，阻尼系数 $\tau$ 降低其影响（通常 $\tau = 0$）。
        - 对于 $t = 1$：$ b_t = g_t $
          - 初始动量直接设为当前梯度。
        - Nesterov 动量:
          - $ \text{if nesterov}: \quad g_t \leftarrow g_t + \mu b_t $
            - 如果启用 Nesterov 动量，计算预测位置的梯度贡献：
            - 标准动量法直接使用 $b_t$ 更新参数。
            - Nesterov 动量法额外加上 $\mu b_t$，模拟在预测位置 $\theta_{t-1} - \mu b_{t-1}$ 处的梯度（实际实现中通过调整公式实现）。
          - $ \text{else}: \quad g_t \leftarrow b_t $
            - 如果不使用 Nesterov，则直接使用动量 $b_t$。
    - 参数更新:
      - $ \text{if maximize}: \quad \theta_t = \theta_{t-1} + \gamma g_t $
      - $ \text{else}: \quad \theta_t = \theta_{t-1} - \gamma g_t $
        - 如果 maximize=True，沿梯度方向更新以最大化目标函数（用于某些任务，如对抗网络）。
        - 否则，沿负梯度方向更新以最小化损失（默认行为）。
      - 返回:
        - $ \text{return } \theta_t $
    - 返回更新后的参数。

- Adadelta
    - torch.optim.Adadelta 是 PyTorch 中实现的 Adadelta 优化算法，基于 Adagrad 的改进，旨在解决 Adagrad 学习率过快衰减的问题。
    - Adadelta 通过指数移动平均（EMA）跟踪梯度平方和更新量的平方，动态调整学习率，无需手动设置全局学习率（尽管仍保留 lr 参数用于微调）。
  - 参数说明:
    - params: 模型的可优化参数（通常是 model.parameters()），即 $\theta_0$。
    - lr: 学习率（$\gamma$），默认 1.0，Adadelta 中作用为缩放因子，通常无需调整。
    - rho: 衰减率（$\rho$），默认 0.9，用于计算梯度平方和更新量的指数移动平均。
    - eps: 小常数（$\epsilon$），默认 1e-06，防止除零，确保数值稳定性。
    - weight_decay: 权重衰减系数（$\lambda$），默认 0，添加 L2 正则化项。
    - foreach: 是否使用 foreach 实现以提高性能（None 表示自动选择）。
    - capturable: 是否支持捕获中间状态（实验性功能，默认 False）。
    - maximize: 布尔值，默认 False，决定优化目标是最大化（True）还是最小化（False）损失函数。
    - differentiable: 是否支持可微优化（实验性功能，默认 False）。
  - 输入参数:
    - $\gamma$: 学习率（lr），在 Adadelta 中主要作为更新量的缩放因子。
    - $\theta_0$: 初始参数（params）。
    - $f(\theta)$: 目标函数（损失函数）。
    - $\rho$: 衰减率（rho），控制指数移动平均的平滑程度。
    - $\lambda$: 权重衰减系数（weight_decay）。
  - 初始化:
    - $v_0 = 0$: 梯度平方的指数移动平均（square avg），初始化为 0。
    - $u_0 = 0$: 更新量平方的指数移动平均（accumulate variables），初始化为 0。
  - 计算梯度:
    - $ g_t = \nabla_\theta f_t(\theta_{t-1}) $
    - 计算当前参数 $\theta_{t-1}$ 处的梯度 $g_t$。
  - 权重衰减:
    - $ \text{if } \lambda \neq 0: \quad g_t \leftarrow g_t + \lambda \theta_{t-1} $
    - 如果设置了权重衰减（$\lambda > 0$），在梯度中加入正则化项 $\lambda \theta_{t-1}$，等效于 L2 正则化。
  - 更新梯度平方期望:
    - $ v_t = \rho v_{t-1} + (1 - \rho) g_t^2 $
    - 计算梯度平方的指数移动平均 $v_t$，其中：
    - $\rho v_{t-1}$: 保留历史梯度平方的信息。
    - $(1 - \rho) g_t^2$: 当前梯度平方的贡献。
    - $v_t$ 估计梯度的“强度”，类似 RMSprop 的二阶动量。
  - 计算更新量:
    - $ \Delta x_t = \frac{\sqrt{u_{t-1} + \epsilon}}{\sqrt{v_t + \epsilon}} g_t $
    - 更新量 $\Delta x_t$ 基于梯度 $g_t$，通过前一步更新量平方期望 $u_{t-1}$ 和当前梯度平方期望 $v_t$ 进行归一化。
    - $\sqrt{v_t + \epsilon}$: 估计梯度的标准差，用于缩放梯度。
    - $\sqrt{u_{t-1} + \epsilon}$: 前一步更新量的标准差，保持量纲一致。
    - $\epsilon$: 防止除零。
  - 更新更新量平方期望:
    - $ u_t = \rho u_{t-1} + (1 - \rho) \Delta x_t^2 $
    - 计算更新量平方的指数移动平均 $u_t$，用于下一轮更新量的归一化。
  - 参数更新:
    - $ \theta_t = \theta_{t-1} - \gamma \Delta x_t $
    - 使用学习率 $\gamma$ 缩放更新量 $\Delta x_t$，更新参数。
    - 如果 maximize=True，则改为 $\theta_t = \theta_{t-1} + \gamma \Delta x_t$（未在伪代码中体现，但由参数 maximize 控制）。
  - 返回:
    - $ \text{return } \theta_t $
    - 返回更新后的参数

- Adam
  - 介绍: 
     - Adam 结合动量法和 RMSprop，适应性强，广泛应用于深度学习。
  - 公式:
    - 一阶动量:
      - $m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t $
    - 二阶动量:
      - $v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2 $
    - 偏差修正:
      - $\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1-\beta_2^t} $
    - 参数更新:
      - $\theta_{t+1} = \theta_t - \eta \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $
  - 计算过程:
    计算梯度 $g_t$。
    - 更新一阶动量 $m_t$ 和二阶动量 $v_t$。
    - 进行偏差修正，得到 $\hat{m}_t$ 和 $\hat{v}_t$。
    - 使用自适应学习率更新参数。
    - 特点: 收敛快，适合非平稳目标。
- AdamW
  - 介绍: AdamW 是 Adam 的正则化版本，通过解耦权重衰减提高泛化能力。
  - 公式:
    - 同 Adam，但参数更新加入权重衰减:
    - $\theta_{t+1} = \theta_t - \eta \cdot \left( \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} + \lambda \theta_t \right) $
  - 计算过程:
    - 同 Adam 计算 $m_t$, $v_t$, $\hat{m}_t$, $\hat{v}_t$。
    - 在更新中加入权重衰减项 $\lambda \theta_t$。
  - 特点: 比 Adam 更适合需要正则化的任务。
- AMSGrad
- RMSProp
  - 介绍: RMSprop 通过指数移动平均调整学习率，解决 Adagrad 学习率衰减问题。
  - 公式:
    - 梯度平方期望:
      - $E[g^2]_t = \rho E[g^2]_{t-1} + (1-\rho) g_t^2 $
    - 参数更新:
      - $\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \cdot g_t $
  - 计算过程:
    - 计算梯度 $g_t$。
    - 更新 $E[g^2]_t$。
    - 使用自适应学习率更新参数。
  - 特点: 适合非平稳目标，收敛较快。
- Adafactor
- RMSprop
  - 介绍: RMSprop 通过指数移动平均调整学习率，解决 Adagrad 学习率衰减问题。
  - 公式:
    - 梯度平方期望:
      - $E[g^2]_t = \rho E[g^2]_{t-1} + (1-\rho) g_t^2 $
  - 参数更新:
    - $\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \cdot g_t $
    - 计算过程:
      - 计算梯度 $g_t$。
      - 更新 $E[g^2]_t$。
      - 使用自适应学习率更新参数。
    - 特点: 适合非平稳目标，收敛较快。
### 归一化
- LayerNorm  层归一化 用于Transformmer
- RMSNorm 均方根归一化，收敛优于LayerNorm，速度快, 用于Transformmer
- 
### 激活函数
- sigmoid 二分类
- tanh 双曲正切函数
- Relu 修正线性单元
- Leaky Relu 
- PReLU
- ELU
- GELU
  - GELU(x)=0.5∗x∗(1+Tanh( 
2/π
​
 ∗(x+0.044715∗x 
3
 )))
- SiLU
- Softmax
- Softplus
  - ln(1 + ex)
- Mish
  - Mish(x)=x∗Tanh(Softplus(x))

### Autograd
PyTorch 的 **Autograd** 功能是自动微分引擎，用于：
- **自动跟踪**：对 `requires_grad=True` 的张量操作，动态构建计算图。
- **自动梯度计算**：通过 `.backward()` 手动触发反向传播，基于链式法则计算梯度。
- **[灵活控制]()**：支持 `torch.no_grad()`、`.detach()` 等禁用或调整梯度跟踪。
- 




# 中文精简描述,生成思维导图
- 如何解决过拟合，欠拟合
- 
- 如何解决梯度爆炸，梯度消失
- 如何提高收敛
- RNN和 CNN的区别
- 激活函数的区别
- 优化器的区别
- 损失函数的区别
- 线性回归和逻辑回归的区别
- 监督训练和无监督训练的区别
- 微调技术的区别
- L1和L2的区别
- 归一化的区别
- 
# 数据噪声
- **常见的噪声类型**
  - 根据数据类型和任务，噪声可以分为：
    - **文本数据噪声**：拼写错误、语法错误、语义模糊、重复内容或无关文本。
    - **图像数据噪声**：模糊、失真、遮挡、错误标注或背景干扰。
    - **语音数据噪声**：背景噪音、录音失真、标注时间戳错误等。
    - **结构化数据噪声**：缺失值、异常值、格式不一致等。
- **应对数据噪声的方法**
  - 为了减轻数据噪声的影响，通常采用以下策略：
    - **数据清洗**：通过规则或算法移除或修正错误数据，如去重、拼写校正、异常值检测。
    - **数据增强**：通过生成高质量的合成数据或数据变换，稀释噪声的影响。
    - **鲁棒性训练**：设计对噪声不敏感的模型，如添加正则化、Dropout或对抗训练。
    - **噪声标签建模**：在训练中显式建模噪声分布，调整损失函数以降低噪声影响。
    - **高质量数据筛选**：优先使用高质量、经过验证的数据子集进行训练。
    - **预处理与标准化**：统一数据格式，减少格式不一致带来的噪声。
# 误差函数
- 误差函数的定义
误差函数 erf(x) 定义为：
$$\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} \, dt$$

- 它是一个奇函数，即 $\text{erf}(-x) = -\text{erf}(x)$。
- 当 $x \to \infty$ 时，$\text{erf}(x) \to 1$；当 $x \to -\infty$ 时，$\text{erf}(x) \to -1$。
- 当 $x = 0$ 时，$\text{erf}(0) = 0$。
# 累积分布函数(CDF)

$\Phi(x) = \frac{1}{2} \left(1 + \text{erf}\left(\frac{x}{\sqrt{2}}\right)\right)$
